[
  {
    "id": 1097,
    "file_path": "src/main/java/org/apache/commons/compress/archivers/tar/TarArchiveInputStream.java",
    "start-bug-line": 462,
    "end-bug-line": 462,
    "bug": "if (ch == ' '){",
    "fix": "if (ch == '\\n') { // blank line in header break; } else if (ch == ' '){ // End of length string",
    "fixes": [],
    "err": "",
    "ctxs": [
      {
        "txt": "package org.apache.commons.compress.archivers.tar; import java.io.ByteArrayOutputStream;"
      },
      {
        "txt": "import java.io.IOException; import java.io.InputStream; import java.util.HashMap; import java.util.Map; import java.util.Map.Entry; import org.apache.commons.compress.archivers.ArchiveEntry; import org.apache.commons.compress.archivers.ArchiveInputStream; import org.apache.commons.compress.archivers.zip.ZipEncoding; import org.apache.commons.compress.archivers.zip.ZipEncodingHelper; import org.apache.commons.compress.utils.ArchiveUtils;"
      },
      {
        "txt": "import org.apache.commons.compress.utils.CharsetNames; import org.apache.commons.compress.utils.IOUtils; public class TarArchiveInputStream extends ArchiveInputStream { private static final int SMALL_BUFFER_SIZE = 256; private final byte[] SMALL_BUF = new byte[SMALL_BUFFER_SIZE]; private final int recordSize; private final int blockSize; private boolean hasHitEOF; private long entrySize; private long entryOffset;"
      },
      {
        "txt": "private final InputStream is; private TarArchiveEntry currEntry; private final ZipEncoding zipEncoding; final String encoding; private Map<String, String> globalPaxHeaders = new HashMap<String, String>(); public TarArchiveInputStream(final InputStream is) { this(is, TarConstants.DEFAULT_BLKSIZE, TarConstants.DEFAULT_RCDSIZE); } public TarArchiveInputStream(final InputStream is, final String encoding) { this(is, TarConstants.DEFAULT_BLKSIZE, TarConstants.DEFAULT_RCDSIZE,"
      },
      {
        "txt": "encoding); } public TarArchiveInputStream(final InputStream is, final int blockSize) { this(is, blockSize, TarConstants.DEFAULT_RCDSIZE); } public TarArchiveInputStream(final InputStream is, final int blockSize, final String encoding) { this(is, blockSize, TarConstants.DEFAULT_RCDSIZE, encoding); } public TarArchiveInputStream(final InputStream is, final int blockSize, final int recordSize) {"
      },
      {
        "txt": "this(is, blockSize, recordSize, null); } public TarArchiveInputStream(final InputStream is, final int blockSize, final int recordSize, final String encoding) { this.is = is; this.hasHitEOF = false; this.encoding = encoding; this.zipEncoding = ZipEncodingHelper.getZipEncoding(encoding); this.recordSize = recordSize; this.blockSize = blockSize;"
      },
      {
        "txt": "} @Override public void close() throws IOException { is.close(); } public int getRecordSize() { return recordSize; } @Override public int available() throws IOException {"
      },
      {
        "txt": "if (isDirectory()) { return 0; } if (entrySize - entryOffset > Integer.MAX_VALUE) { return Integer.MAX_VALUE; } return (int) (entrySize - entryOffset); } @Override public long skip(final long n) throws IOException {"
      },
      {
        "txt": "if (n <= 0 || isDirectory()) { return 0; } final long available = entrySize - entryOffset; final long skipped = is.skip(Math.min(n, available)); count(skipped); entryOffset += skipped; return skipped; } @Override"
      },
      {
        "txt": "public boolean markSupported() { return false; } @Override public void mark(final int markLimit) { } @Override public synchronized void reset() { } public TarArchiveEntry getNextTarEntry() throws IOException {"
      },
      {
        "txt": "if (hasHitEOF) { return null; } if (currEntry != null) { IOUtils.skip(this, Long.MAX_VALUE); skipRecordPadding(); } final byte[] headerBuf = getRecord(); if (headerBuf == null) { currEntry = null;"
      },
      {
        "txt": "return null; } try { currEntry = new TarArchiveEntry(headerBuf, zipEncoding); } catch (final IllegalArgumentException e) { throw new IOException(\"Error detected parsing the header\", e); } entryOffset = 0; entrySize = currEntry.getSize(); if (currEntry.isGNULongLinkEntry()) {"
      },
      {
        "txt": "final byte[] longLinkData = getLongNameData(); if (longLinkData == null) { return null; } currEntry.setLinkName(zipEncoding.decode(longLinkData)); } if (currEntry.isGNULongNameEntry()) { final byte[] longNameData = getLongNameData(); if (longNameData == null) { return null;"
      },
      {
        "txt": "} currEntry.setName(zipEncoding.decode(longNameData)); } if (currEntry.isGlobalPaxHeader()){ // Process Global Pax headers readGlobalPaxHeaders(); } if (currEntry.isPaxHeader()){ // Process Pax headers paxHeaders(); } else if (!globalPaxHeaders.isEmpty()) { applyPaxHeadersToCurrentEntry(globalPaxHeaders);"
      },
      {
        "txt": "} if (currEntry.isOldGNUSparse()){ // Process sparse files readOldGNUSparse(); } entrySize = currEntry.getSize(); return currEntry; } private void skipRecordPadding() throws IOException { if (!isDirectory() && this.entrySize > 0 && this.entrySize % this.recordSize != 0) { final long numRecords = (this.entrySize / this.recordSize) + 1;"
      },
      {
        "txt": "final long padding = (numRecords * this.recordSize) - this.entrySize; final long skipped = IOUtils.skip(is, padding); count(skipped); } } protected byte[] getLongNameData() throws IOException { final ByteArrayOutputStream longName = new ByteArrayOutputStream(); int length = 0; while ((length = read(SMALL_BUF)) >= 0) { longName.write(SMALL_BUF, 0, length);"
      },
      {
        "txt": "} getNextEntry(); if (currEntry == null) { return null; } byte[] longNameData = longName.toByteArray(); length = longNameData.length; while (length > 0 && longNameData[length - 1] == 0) { --length; }"
      },
      {
        "txt": "if (length != longNameData.length) { final byte[] l = new byte[length]; System.arraycopy(longNameData, 0, l, 0, length); longNameData = l; } return longNameData; } private byte[] getRecord() throws IOException { byte[] headerBuf = readRecord(); hasHitEOF = isEOFRecord(headerBuf);"
      },
      {
        "txt": "if (hasHitEOF && headerBuf != null) { tryToConsumeSecondEOFRecord(); consumeRemainderOfLastBlock(); headerBuf = null; } return headerBuf; } protected boolean isEOFRecord(final byte[] record) { return record == null || ArchiveUtils.isArrayZero(record, recordSize); }"
      },
      {
        "txt": "protected byte[] readRecord() throws IOException { final byte[] record = new byte[recordSize]; final int readNow = IOUtils.readFully(is, record); count(readNow); if (readNow != recordSize) { return null; } return record; } private void readGlobalPaxHeaders() throws IOException {"
      },
      {
        "txt": "globalPaxHeaders = parsePaxHeaders(this); getNextEntry(); // Get the actual file entry } private void paxHeaders() throws IOException{ final Map<String, String> headers = parsePaxHeaders(this); getNextEntry(); // Get the actual file entry applyPaxHeadersToCurrentEntry(headers); } Map<String, String> parsePaxHeaders(final InputStream i) throws IOException {"
      },
      {
        "txt": "while(true){ // get length int ch; int len = 0; int read = 0; while((ch = i.read()) != -1) { read++; <extra_id_0> final ByteArrayOutputStream coll = new ByteArrayOutputStream(); while((ch = i.read()) != -1) { read++; if (ch == '='){ // end of keyword final String keyword = coll.toString(CharsetNames.UTF_8); final int restLen = len - read;"
      },
      {
        "txt": "final String keyword = coll.toString(CharsetNames.UTF_8); final int restLen = len - read; if (restLen == 1) { // only NL headers.remove(keyword); } else { final byte[] rest = new byte[restLen]; final int got = IOUtils.readFully(i, rest); if (got != restLen) { throw new IOException(\"Failed to read \" + \"Paxheader. Expected \""
      },
      {
        "txt": "+ restLen + \" bytes, read \" + got); } final String value = new String(rest, 0, restLen - 1, CharsetNames.UTF_8); headers.put(keyword, value); } break; }"
      },
      {
        "txt": "coll.write((byte) ch); } break; // Processed single header } len *= 10; len += ch - '0'; } if (ch == -1){ // EOF break; }"
      },
      {
        "txt": "} return headers; } private void applyPaxHeadersToCurrentEntry(final Map<String, String> headers) { for (final Entry<String, String> ent : headers.entrySet()){ final String key = ent.getKey(); final String val = ent.getValue(); if (\"path\".equals(key)){ currEntry.setName(val); } else if (\"linkpath\".equals(key)){"
      },
      {
        "txt": "currEntry.setLinkName(val); } else if (\"gid\".equals(key)){ currEntry.setGroupId(Long.parseLong(val)); } else if (\"gname\".equals(key)){ currEntry.setGroupName(val); } else if (\"uid\".equals(key)){ currEntry.setUserId(Long.parseLong(val)); } else if (\"uname\".equals(key)){ currEntry.setUserName(val); } else if (\"size\".equals(key)){"
      },
      {
        "txt": "currEntry.setSize(Long.parseLong(val)); } else if (\"mtime\".equals(key)){ currEntry.setModTime((long) (Double.parseDouble(val) * 1000)); } else if (\"SCHILY.devminor\".equals(key)){ currEntry.setDevMinor(Integer.parseInt(val)); } else if (\"SCHILY.devmajor\".equals(key)){ currEntry.setDevMajor(Integer.parseInt(val)); } else if (\"GNU.sparse.size\".equals(key)) { currEntry.fillGNUSparse0xData(headers); } else if (\"GNU.sparse.realsize\".equals(key)) {"
      },
      {
        "txt": "currEntry.fillGNUSparse1xData(headers); } else if (\"SCHILY.filetype\".equals(key) && \"sparse\".equals(val)) { currEntry.fillStarSparseData(headers); } } } private void readOldGNUSparse() throws IOException { sparses = new ArrayList(); sparses.addAll(currEntry.getSparses()); if (currEntry.isExtended()) {"
      },
      {
        "txt": "TarArchiveSparseEntry entry; do { final byte[] headerBuf = getRecord(); if (headerBuf == null) { currEntry = null; break; } entry = new TarArchiveSparseEntry(headerBuf); sparses.addAll(entry.getSparses()); } while (entry.isExtended());"
      },
      {
        "txt": "} } private boolean isDirectory() { return currEntry != null && currEntry.isDirectory(); } @Override public ArchiveEntry getNextEntry() throws IOException { return getNextTarEntry(); } private void tryToConsumeSecondEOFRecord() throws IOException {"
      },
      {
        "txt": "boolean shouldReset = true; final boolean marked = is.markSupported(); if (marked) { is.mark(recordSize); } try { shouldReset = !isEOFRecord(readRecord()); } finally { if (shouldReset && marked) { pushedBackBytes(recordSize);"
      },
      {
        "txt": "is.reset(); } } } @Override public int read(final byte[] buf, final int offset, int numToRead) throws IOException { int totalRead = 0; if (hasHitEOF || isDirectory() || entryOffset >= entrySize) { return -1; }"
      },
      {
        "txt": "if (currEntry == null) { throw new IllegalStateException(\"No current tar entry\"); } numToRead = Math.min(numToRead, available()); totalRead = is.read(buf, offset, numToRead); if (totalRead == -1) { if (numToRead > 0) { throw new IOException(\"Truncated TAR archive\"); } hasHitEOF = true;"
      },
      {
        "txt": "} else { count(totalRead); entryOffset += totalRead; } return totalRead; } @Override public boolean canReadEntryData(final ArchiveEntry ae) { if (ae instanceof TarArchiveEntry) { final TarArchiveEntry te = (TarArchiveEntry) ae;"
      },
      {
        "txt": "return !te.isSparse(); } return false; } public TarArchiveEntry getCurrentEntry() { return currEntry; } protected final void setCurrentEntry(final TarArchiveEntry e) { currEntry = e; }"
      },
      {
        "txt": "protected final boolean isAtEOF() { return hasHitEOF; } protected final void setAtEOF(final boolean b) { hasHitEOF = b; } private void consumeRemainderOfLastBlock() throws IOException { final long bytesReadOfLastBlock = getBytesRead() % blockSize; if (bytesReadOfLastBlock > 0) { final long skipped = IOUtils.skip(is, blockSize - bytesReadOfLastBlock);"
      },
      {
        "txt": "count(skipped); } } public static boolean matches(final byte[] signature, final int length) { if (length < TarConstants.VERSION_OFFSET+TarConstants.VERSIONLEN) { return false; } if (ArchiveUtils.matchAsciiBuffer(TarConstants.MAGIC_POSIX, signature, TarConstants.MAGIC_OFFSET, TarConstants.MAGICLEN) &&"
      },
      {
        "txt": "ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_POSIX, signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN) ){ return true; } if (ArchiveUtils.matchAsciiBuffer(TarConstants.MAGIC_GNU, signature, TarConstants.MAGIC_OFFSET, TarConstants.MAGICLEN) && ( ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_GNU_SPACE,"
      },
      {
        "txt": "signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN) || ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_GNU_ZERO, signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN) ) ){ return true; } if (ArchiveUtils.matchAsciiBuffer(TarConstants.MAGIC_ANT, signature, TarConstants.MAGIC_OFFSET, TarConstants.MAGICLEN)"
      },
      {
        "txt": "&& ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_ANT, signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN) ){ return true; } return false; }"
      }
    ]
  }
]